---
title: "Assignment V: GitHub and the ticketmaster.com API"
subtitle: "Data Science Project Management | Winter Term 2020/21"
author: "Submitted by Franziska MÃ¼ller (Student ID: 5401673)"
date: "February, 16, 2021"
output: 
  html_document:
  toc: true
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
I hereby assure that my submission is in line with the *Code of Conduct* outlined on the lecture slides. I worked on my own.

## General setup

Before I start the project, I clear my workspace. 
# Note regarding key and maybe working directory

```{r preparation, message = FALSE, warning = FALSE}
# Clear workspace
rm(list = ls())

# Source private key - insert yout indicidual path to the key
source("C:/Users/Francesca/Desktop/MA_WiSe 202021/Data Science Project Management/Assignments/key_ticketmaster.R")
```

## Exercise 1: Setting up a GitHub repository
Please find my repository via: https://github.com/FrancescaMueller/DSPM_AssignmentV.git

## Exercise 2: Getting to know the API
Rate limit is given by 5 requests per second and max. 5,000 requests per day.

## Exercise 3: Interacting with the API - the basics

*Load the packages needed to interact with APIs using R.*
```{r packages, message = FALSE, warning = FALSE}
# Check if packages have been installed before; if not, install them
if (!require("jsonlite")) install.packages("jsonlite")
if (!require("httr")) install.packages("httr")
if (!require("rlist")) install.packages("rlist")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("tidyr")) install.packages("tidyr")
if (!require("dplyr")) install.packages("dplyr")

# Load packages
library(jsonlite) 
library(dplyr)
library(httr)
library(rlist)
library(tidyverse)
library(tidyr)
```

*Perform a first GET request, that searches for event venues in Germany (countryCode = "DE"). Extract the content from the response object and inspect the resulting list. Describe what you can see.*

```{r first_GET_request}

my_url <- paste0("https://app.ticketmaster.com/discovery/v2/venues?apikey=", key)

first_glimpse <- function(country, page) {
  resp_obj <- GET(url = paste0(my_url, 
                               "&locale=*&page=", 
                               page, 
                               "&countryCode=", 
                               country))
  cont_obj <- resp_obj %>% content()
  return(cont_obj)
}

country <- 'DE'
Ex3_first_glimpse <- first_glimpse(country, 0)
# Use page = 0 in order to get the first 20 results

```
The resulting content object is a list with nested structure. It contains the lists named ``r names(Ex3_cont_obj)[1]``, ``r names(Ex3_cont_obj)[2]`` and `` names(Ex3_cont_obj)[3]``. The first one covers different venues and detailed information about a specific venue such as name, type, postal code etc. Interesting here, the lists have different lenghts. Therefore, not every information is given for every venue.
The second one contains links regarding the first, self (actual scraped page), next and last page. Here, it is shown that there are 3465 elements in total with 20 results each. In the last one also information about pages and results is given but just the raw information without the respective url. Again, there are ``r Ex3_cont_obj[["page"]][["totalPages"]]`` pages with ``r Ex3_cont_obj[["page"]][["size"]]`` elements each (in total: ``r Ex3_cont_obj[["page"]][["totalElements"]]`` elements).


*Extract 'name', 'city', 'postalCode', 'adress', 'url', longitude', 'latitude'.*
```{r get_content_function, warning = FALSE}
my_url <- paste0("https://app.ticketmaster.com/discovery/v2/venues?apikey=", key)
country <- "DE"

# Function GET CONTENT
get_content <- function(country, page) {
  # Note_ n encoding supplied: defaulting to UTF8
  resp_obj <- GET(url = paste0(my_url, 
                               "&locale=*&page=", 
                               page, 
                               "&countryCode=", 
                               country))
  cont_obj <- fromJSON(content(x = resp_obj, 
                               as = 'text'))
  
  # Keep just relevant information about venues in general 
  placeholder <- as.data.frame(cont_obj$`_embedded`$venues)
  
  # Just keep relevant information asked by the assignment
  df <- data.frame(placeholder$name, placeholder$city[1],
                   placeholder$postalCode, placeholder$address, placeholder$url
                   )
  
  # Adjust for location
  if (is.null(placeholder$location) == TRUE) {
    df['longitude'] <- NA
    df['latitude'] <- NA
  } else{
    df <- df %>% cbind(placeholder$location[1], placeholder$location[2])
  }
  
  # Rename columns
  names(df) <- c("name", "city", "postalCode", "address", "url", "longitude", "latitude")
  
  # Change longitude and latitude to type double
  df$longitude <- df$longitude %>% as.double()
  df$latitude <- df$latitude %>% as.double()
  
  return(df)
}

Ex3 <- get_content(country, 0)

```

## Exercise 4: Interacting with the API - advanced

*Have a closer look at the element list named ``page``.*
There are ``r Ex3_cont_obj[["page"]][["totalPages"]]`` pages with ``r Ex3_cont_obj[["page"]][["totalElements"]]`` elements in total. 
Note: The loop must be enriched with further statements to get the elements from the last page
Use the parameter ``page`` to access the different pages. 

```{r Ex_4, warning = FALSE}
pages <- as.numeric(Ex3_first_glimpse[["page"]][["totalPages"]])  # Number of total pages
pages_loop <- pages - 1 # Counting from 0 to 611, in total 612 pages
n <- as.numeric(nrow(Ex3))  # Number of elements per page
m <- as.numeric(Ex3_first_glimpse[["page"]][["totalElements"]])  # number total elements

# Controlling for remainder
pages_control <- floor(m/n) # 611 pages
# Controlling for possible remainder
remainder <- m - floor(m/n)*n  # 18 
last_page <- ceiling(m/n)  # 612
# Note: need to consider last page as special case since the function all_pages cannot handle df with less than n = 20 rows


# Create empty data frame
df_Ex4 <- tibble(name = character(m),
                 city = character(m),
                 postalCode = character(m),
                 adress = character(m),
                 url = character(m),
                 longitude = double(m),
                 latitude = double(m))

# Loop 
all_pages <- function(country, number_pages, df_all_pages) {
  for (j in 0:number_pages) {
    tryCatch({  
      # added since very error prone
      cont_obj <- get_content(country, j)
      df_all_pages[(20 + 20 * j - 19):(20 + 20 * j),] <- cont_obj
      Sys.sleep(time = 0.3)  # 5 requests per second allowed, but adjusted since error prone
    },
    error = function(e){})
  }
  return(df_all_pages)
  }

# Get info all pages
system.time(
  Ex4_all <- all_pages(country, pages_loop, df_Ex4),
  # Add infor for last page
  Ex4_all[12221:m,] <- get_content(country, pages_loop)
) # 245.65 sec


# Save created data frame
# saveRDS(Ex4_all, file = "./data_DE.rds")

```

## Exercise 5: Visualizing the extended data

```{r visualization_DE}
# Prepare data frame
# Note: filter() would be more effective but the assigment asks to assign NA to unwanted data - so first, NAs will be introduced, second, df will adapted to purpose (remove rows containing NAs in longitude/latitude column etc.).

Ex5 <- Ex4_all %>% mutate(longitude = replace(
  x = longitude,
  list = longitude < 5.86694,
  values = NA
))
Ex5 <- Ex5 %>% mutate(longitude = replace(
  x = longitude,
  list = longitude > 15.043611,
  values = NA
))

Ex5 <- Ex5 %>% mutate(latitude = replace(
  x = latitude,
  list = latitude < 47.271679,
  values = NA
))

Ex5 <- Ex5 %>% mutate(latitude = replace(
  x = latitude,
  list = latitude > 55.0846,
  values = NA
))

# Remove unneded rows for the plot
Ex5_plot <- Ex5[complete.cases(Ex5[ , 6:7]), ]

# Control
max(Ex5_plot$longitude) <= 15.043611
max(Ex5_plot$latitude) <= 55.0846
min(Ex5_plot$longitude) >= 5.86694
min(Ex5_plot$latitude) >= 47.271679
# Note: Although location data was adjusted to suggested range some vlaues will be outside the borders

# Plot 
plot_DE <- ggplot() +
  geom_polygon(
    aes(x = long, y = lat, group = group),
    data = map_data("world", region = "Germany"),
    fill = "grey90",
    color = "black"
  ) +
  geom_point(mapping = aes(x = longitude,
                           y = latitude), 
             data = Ex5_plot,
             color = "purple",
             alpha = 0.1) + 
  theme_void() + coord_quickmap() +
  labs(title = "Event locations across Germany", caption = "Source: ticketmaster.com") +
  theme(title = element_text(size = 8, face = 'bold'),
        plot.caption = element_text(face = "italic"))

plot_DE
# Save the plot in the end
# ggsave('plot_DE.jpeg') 

```

## Exercise 6: Event locations in other countries

```{r different_country, warning = FALSE}
# Choosing a small country with fewer observations -> Belgium

# Repeat Ex.2
# Same as above.

# Repeat Ex.3
Ex3_first_glimpse_BE <- first_glimpse("BE", 0)  # Compared to Germany: small data set
```
Describtion: Again, the objected is nested and covers three different aspects(_embedded, _links, page) which are nested, too. The structure is same as before in Ex.2. Relevant information for the Exercise can be accessed via ``Ex3_first_glimpse_BE[["_embedded"]][["venues"]]``. Here, there are ``r Ex3_first_glimpse_BE[["page"]][["totalPages"]]`` pages with mostly ``r Ex3_first_glimpse_BE[["page"]][["size"]]`` elements each, in total ``r Ex3_first_glimpse_BE[["page"]][["totalElements"]]``. 

```{r Ex6}
# Repaet Ex.3
Ex3_BE <- get_content('BE', 0)

# Repeat Ex.4
pages_BE <- as.numeric(Ex3_first_glimpse_BE[["page"]][["totalPages"]])
pages_loop_BE <- pages_BE - 1
m_BE <- as.numeric(Ex3_first_glimpse_BE[["page"]][["totalElements"]])

# Control for remainder
pages_BE == floor(m_BE/n)  # FALSE
# Thereofre, need to account for last page

# Prepare data frame
df_Ex4_BE <- tibble(name = character(m_BE),
                 city = character(m_BE),
                 postalCode = character(m_BE),
                 adress = character(m_BE),
                 url = character(m_BE),
                 longitude = double(m_BE),
                 latitude = double(m_BE))
system.time(
  Ex4_all_BE <- all_pages(country = "BE",
                     number_pages = pages_BE,
                     df_all_pages = df_Ex4_BE),
  # Account for last page
  Ex4_all_BE[1021:m_BE, ] <- get_content('BE', pages_loop_BE)
  )  # 26.22  sec

# Save created data frame
# saveRDS(Ex4_all_BE, file = "./data_BE.rds")

# Looking up the ranges
# long = 51.496877 (lat 4.775462)
# long = 49.508076 (5.474041)  #Torgny
# 51.096279, 2.590563  # De Panne
# 50.331120, 6.382170 # Krewinkel

# Prepare df for plot
Ex5_BE <- Ex4_all_BE %>% mutate(longitude = replace(
  x = longitude,
  list = longitude < 2.590563,  # BE
  values = NA
))
Ex5_BE <- Ex4_all_BE %>% mutate(longitude = replace(
  x = longitude,
  list = longitude > 6.382170,  # BE
  values = NA
))

Ex5_BE <- Ex4_all_BE %>% mutate(latitude = replace(
  x = latitude,
  list = latitude < 49.508076,  # BE
  values = NA
))

Ex5_BE <- Ex4_all_BE %>% mutate(latitude = replace(
  x = latitude,
  list = latitude > 51.496877,  # BE
  values = NA
))

# Remove unneded rows for the plot
Ex5_plot_BE <- Ex5_BE[complete.cases(Ex5_BE[ , 6:7]), ]

# Plot 
plot_BE <- ggplot() +
  geom_polygon(
    aes(x = long, y = lat, group = group),
    data = map_data("world", region = "Belgium"),
    fill = "grey90",
    color = "black"
  ) +
  geom_point(mapping = aes(x = longitude,
                           y = latitude), 
             data = Ex5_plot_BE,
             color = "purple",
             alpha = 0.3) + 
  theme_void() + coord_quickmap() +
  labs(title = "Event locations across Belgium", caption = "Source: ticketmaster.com") +
  theme(title = element_text(size = 8, face = 'bold'),
        plot.caption = element_text(face = "italic"))

# map_data("world", region = "Belgium")
```
